{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "### training dataset ###\n",
    "train_path = r'./training'\n",
    "train_all_files = glob.glob(train_path + \"/*.csv\")\n",
    "train_list = []\n",
    "\n",
    "for filename in train_all_files:\n",
    "    reader = pd.read_csv(filename, index_col=None, header=0,nrows=10000,low_memory=False)\n",
    "    train_list.append(reader)\n",
    "\n",
    "train_df = pd.concat(train_list, axis=0, ignore_index=True)\n",
    "\n",
    "train_df[' Label'] = train_df[' Label'].replace({'BENIGN':0,'DrDoS_NTP':1,'TFTP':1,'Syn':2,'DrDoS_DNS':1,'DrDoS_LDAP':1,'DrDoS_NetBIOS':1,'DrDoS_SNMP':1,'UDP-lag':2,\\\n",
    "                                                'DrDoS_SSDP':1,'DrDoS_MSSQL':1,'DrDoS_UDP':2,'WebDDoS':1})\n",
    "### testing dataset ###\n",
    "test_path = r'./testing'\n",
    "test_all_files = glob.glob(test_path + \"/*.csv\")\n",
    "test_list = []\n",
    "\n",
    "for filename in test_all_files:\n",
    "    reader = pd.read_csv(filename, index_col=None, header=0,nrows=10000,low_memory=False)\n",
    "    test_list.append(reader)\n",
    "\n",
    "test_df = pd.concat(test_list, axis=0, ignore_index=True)\n",
    "                             \n",
    "test_df[' Label'] = test_df[' Label'].replace({'BENIGN':0,'Syn':2,'LDAP':1,'NetBIOS':1,'Portmap':1,\\\n",
    "                                                'MSSQL':1,'UDP':2})\n",
    "\n",
    "### training cluster dataset ###\n",
    "train_cluster_path = r'./training_clustering'\n",
    "train_cluster_files = glob.glob(train_cluster_path + \"/*.csv\")\n",
    "train_cluster_list = []\n",
    "\n",
    "for filename in train_cluster_files:\n",
    "    reader = pd.read_csv(filename, index_col=None, header=0,nrows=10000,low_memory=False)\n",
    "    train_cluster_list.append(reader)\n",
    "    \n",
    "train_cluster_df = pd.concat(train_cluster_list, axis=0, ignore_index=True)\n",
    "\n",
    "train_cluster_df[' Label'] = train_cluster_df[' Label'].replace({'BENIGN':0,'DrDoS_NTP':1,'TFTP':1,'Syn':2,'DrDoS_DNS':1,'DrDoS_LDAP':1,'DrDoS_NetBIOS':1,'DrDoS_SNMP':1,'UDP-lag':2,\\\n",
    "                                                'DrDoS_SSDP':1,'DrDoS_MSSQL':1,'DrDoS_UDP':2,'WebDDoS':1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid(clf, fuzzy_threshold, preproc):\n",
    "    ### Classification with all data\n",
    "    X_train = train_df[[' ACK Flag Count',\n",
    "                        ' Fwd Packet Length Std',\n",
    "                        ' Packet Length Std',\n",
    "                        'Fwd Packets/s',\n",
    "                        ' Protocol',\n",
    "                        ' Flow Duration']].values\n",
    "    y_train = train_df[' Label'].values\n",
    "\n",
    "    X_test = test_df[[' ACK Flag Count',\n",
    "                      ' Fwd Packet Length Std',\n",
    "                      ' Packet Length Std',\n",
    "                      'Fwd Packets/s',\n",
    "                      ' Protocol',\n",
    "                      ' Flow Duration']].values\n",
    "    y_test = test_df[' Label'].values\n",
    "    \n",
    "    if preproc:\n",
    "        X_train = preprocessing.scale(X_train)\n",
    "        X_test = preprocessing.scale(X_test)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    acc_scr = metrics.accuracy_score(y_pred ,y_test)\n",
    "    cfs_mat = metrics.confusion_matrix(y_pred, y_test)\n",
    "    print(\"# Classification with all Dataset result\")\n",
    "    print(\"Accuracy:\", acc_scr)\n",
    "    print(\"Confusion Metrix:\\n\", cfs_mat)\n",
    "    print()\n",
    "    \n",
    "    ### filter fuzzy data with probability\n",
    "    print(\"Hybrid\")\n",
    "    print(\"=\"*20)\n",
    "    y_pred_proba = clf.predict_proba(X_test)\n",
    "    L1_prob = pd.DataFrame({'y_true':y_test,\n",
    "                            'y_pred':y_pred,\n",
    "                            'y_P(c0)':y_pred_proba[:,0],\n",
    "                            'y_P(c1)':y_pred_proba[:,1],\n",
    "                            'y_P(c2)':y_pred_proba[:,2]})\n",
    "    \n",
    "    # old fuzzy\n",
    "    #     fuzzy_idx = L1_prob[((abs(L1_prob['y_P(c0)'] - 0.5) < 0.1) & (abs(L1_prob['y_P(c1)'] - 0.5) < 0.1)) |\n",
    "    #                         ((abs(L1_prob['y_P(c0)'] - 0.5) < 0.1) & (abs(L1_prob['y_P(c2)'] - 0.5) < 0.1)) |\n",
    "    #                         ((abs(L1_prob['y_P(c1)'] - 0.5) < 0.1) & (abs(L1_prob['y_P(c2)'] - 0.5) < 0.1))].index\n",
    "    \n",
    "    fuzzy_idx = L1_prob[(L1_prob['y_P(c0)'] < fuzzy_threshold) &\n",
    "                        (L1_prob['y_P(c1)'] < fuzzy_threshold) &\n",
    "                        (L1_prob['y_P(c2)'] < fuzzy_threshold)].index\n",
    "    # display(fuzzy_idx)\n",
    "    \n",
    "    ###### Layer 1 Classification ######\n",
    "    L1_test_df = test_df[[' ACK Flag Count',\n",
    "                           ' Fwd Packet Length Std',\n",
    "                           ' Packet Length Std',\n",
    "                           'Fwd Packets/s',\n",
    "                           ' Protocol',\n",
    "                           ' Flow Duration',\n",
    "                           ' Label']].drop(fuzzy_idx)\n",
    "    # display(L1_test_df)\n",
    "\n",
    "\n",
    "    X_test_L1 = L1_test_df[[' ACK Flag Count',\n",
    "                            ' Fwd Packet Length Std',\n",
    "                            ' Packet Length Std',\n",
    "                            'Fwd Packets/s',\n",
    "                            ' Protocol',\n",
    "                            ' Flow Duration']]\n",
    "    y_test_L1 = L1_test_df[' Label']\n",
    "    \n",
    "    if preproc:\n",
    "        X_test_L1 = preprocessing.scale(X_test_L1)\n",
    "        \n",
    "    # display(X_L1_test)\n",
    "\n",
    "    y_pred_L1 = clf.predict(X_test_L1)\n",
    "    # display(y_L1_test, y_L1_pred)\n",
    "    \n",
    "    acc_scr_L1 = metrics.accuracy_score(y_pred_L1, y_test_L1)\n",
    "    cfs_mat_L1 = metrics.confusion_matrix(y_pred_L1, y_test_L1)\n",
    "    \n",
    "    print('# Fuzzy Dataset Size: ', len(fuzzy_idx))\n",
    "    print(\"# Fuzzy Data Division in Confusion Matrix\")\n",
    "    print(cfs_mat - cfs_mat_L1)\n",
    "    print()\n",
    "    \n",
    "    print(\"Hybrid Layer 1: Classification without Fuzzy Dataset Result\")\n",
    "    print(\"=\"*20)\n",
    "    print(\"Accuracy:\", acc_scr_L1)\n",
    "    print(\"Confusion Metrix:\\n\", cfs_mat_L1)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    ###### Layer 2 Clustering ######\n",
    "    ## Train\n",
    "    X_train_L2 = train_cluster_df[[' Packet Length Mean',\n",
    "                                   ' Flow IAT Mean',\n",
    "                                   ' ACK Flag Count',\n",
    "                                   ' Fwd Packet Length Std',\n",
    "                                   'Fwd Packets/s',\n",
    "                                   ' Protocol',\n",
    "                                   ' Flow Duration']]\n",
    "    X_train_L2 = preprocessing.scale(X_train_L2)\n",
    "    y_train_L2 = train_cluster_df[' Label']\n",
    "\n",
    "    # display(X_train_df)\n",
    "    # display(y_train_df)\n",
    "    \n",
    "    ### Test\n",
    "#     L2_test_df = test_df\n",
    "    # display(L2_test_df)\n",
    "    \n",
    "    X_test_L2 = test_df[[' Packet Length Mean',\n",
    "                             ' Flow IAT Mean',\n",
    "                             ' ACK Flag Count',\n",
    "                             ' Fwd Packet Length Std',\n",
    "                             'Fwd Packets/s',\n",
    "                             ' Protocol',\n",
    "                             ' Flow Duration']]\n",
    "    X_test_L2 = pd.DataFrame(preprocessing.scale(X_test_L2)).iloc[fuzzy_idx]\n",
    "    y_test_L2 = test_df[' Label'].iloc[fuzzy_idx]\n",
    "\n",
    "        \n",
    "    # display(X_test_df)\n",
    "    # display(y_test_df)\n",
    "\n",
    "    ### Cluster 200\n",
    "    cluster_num = 200;\n",
    "    kmeans = KMeans(n_clusters=cluster_num, random_state=0, n_jobs=-1).fit(X_train_L2)\n",
    "    y_pred_L2 = kmeans.predict(X_test_L2)\n",
    "\n",
    "    kmeans_out_df = pd.DataFrame({'cluster_labels':kmeans.labels_,'y':y_train_L2})\n",
    "    y_pred_L2_df = pd.DataFrame({'y_pred':y_pred_L2})\n",
    "\n",
    "    pure = 0\n",
    "    for i in range(0,cluster_num):\n",
    "        tmp_df_0 = kmeans_out_df[(kmeans_out_df['cluster_labels']==i) & (kmeans_out_df['y']==0)]\n",
    "        tmp_df_1 = kmeans_out_df[(kmeans_out_df['cluster_labels']==i) & (kmeans_out_df['y']==1)]\n",
    "        tmp_df_2 = kmeans_out_df[(kmeans_out_df['cluster_labels']==i) & (kmeans_out_df['y']==2)]\n",
    "\n",
    "        most_class = max(len(tmp_df_0),len(tmp_df_1),len(tmp_df_2))\n",
    "        pure += most_class\n",
    "\n",
    "        if most_class == len(tmp_df_0):\n",
    "#             display(\"These are class 0:\", y_pred_L2_df[y_pred_L2_df['y_pred'] == i])\n",
    "            y_pred_L2_df['y_pred'] = y_pred_L2_df['y_pred'].replace({i:0})\n",
    "        elif most_class == len(tmp_df_1):\n",
    "#             display(\"These are class 1:\", y_pred_L2_df[y_pred_L2_df['y_pred'] == i])\n",
    "            y_pred_L2_df['y_pred'] = y_pred_L2_df['y_pred'].replace({i:1})\n",
    "        else:\n",
    "#             display(\"These are class 2:\", y_pred_L2_df[y_pred_L2_df['y_pred'] == i])\n",
    "            y_pred_L2_df['y_pred'] = y_pred_L2_df['y_pred'].replace({i:2})\n",
    "\n",
    "#         print('cluster',i ,' class 0 size: ',len(tmp_df_0),' class 1 size: ',len(tmp_df_1),' class 2 size: ',len(tmp_df_2))\n",
    "\n",
    "#     print(pure, len(y_train_L2))\n",
    "    print(\"Hybrid Layer 2: Clustering with Fuzzy Dataset Result\")\n",
    "    print(\"=\"*20)\n",
    "    print('Pure: ', pure/len(y_train_L2))\n",
    "    \n",
    "    acc_scr_L2 = metrics.accuracy_score(y_pred_L2_df['y_pred'], y_test_L2)\n",
    "    cfs_mat_L2 = metrics.confusion_matrix(y_pred_L2_df['y_pred'], y_test_L2)\n",
    "    print(\"Accuracy:\", acc_scr_L2)\n",
    "    print(\"Confusion Metrix:\\n\", cfs_mat_L2)\n",
    "    print()\n",
    "    \n",
    "    ### Hybrid Accuracy\n",
    "    hybrid_acc = (acc_scr_L1 * len(y_test_L1) + acc_scr_L2 * len(y_test_L2)) / len(test_df)\n",
    "    print(\"Hybrid Result\")\n",
    "    print(\"=\"*20)\n",
    "    print(\"Accuracy:\", hybrid_acc)\n",
    "    print(\"Confusion Matrix:\\n\", cfs_mat_L1 + cfs_mat_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "ID3\n",
      "====================\n",
      "# Classification with all Dataset result\n",
      "Accuracy: 0.7987142857142857\n",
      "Confusion Metrix:\n",
      " [[ 4544    93   372]\n",
      " [  360 44896 13158]\n",
      " [    3   104  6470]]\n",
      "\n",
      "Hybrid\n",
      "====================\n",
      "# Fuzzy Dataset Size:  5648\n",
      "# Fuzzy Data Division in Confusion Matrix\n",
      "[[  80    0    0]\n",
      " [  43  106 5063]\n",
      " [   0   27  329]]\n",
      "\n",
      "Hybrid Layer 1: Classification without Fuzzy Dataset Result\n",
      "====================\n",
      "Accuracy: 0.8608124067628046\n",
      "Confusion Metrix:\n",
      " [[ 4464    93   372]\n",
      " [  317 44790  8095]\n",
      " [    3    77  6141]]\n",
      "\n",
      "Hybrid Layer 2: Clustering with Fuzzy Dataset Result\n",
      "====================\n",
      "Pure:  0.9820833333333333\n",
      "Accuracy: 0.972556657223796\n",
      "Confusion Metrix:\n",
      " [[ 100    0    0]\n",
      " [  10    1    0]\n",
      " [  13  132 5392]]\n",
      "\n",
      "Hybrid Result\n",
      "====================\n",
      "Accuracy: 0.8698285714285714\n",
      "Confusion Matrix:\n",
      " [[ 4564    93   372]\n",
      " [  327 44791  8095]\n",
      " [   16   209 11533]]\n"
     ]
    }
   ],
   "source": [
    "### ID3 + Kmeans\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"ID3\")\n",
    "print(\"=\"*20)\n",
    "\n",
    "clf_ID3 = DecisionTreeClassifier(criterion='entropy')\n",
    "fuzzy_data_threshold = 0.6\n",
    "\n",
    "hybrid(clf_ID3, fuzzy_data_threshold, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Naive Bayes\n",
      "====================\n",
      "# Classification with all Dataset result\n",
      "Accuracy: 0.7906428571428571\n",
      "Confusion Metrix:\n",
      " [[  880    44     0]\n",
      " [ 3605 44469 10004]\n",
      " [  422   580  9996]]\n",
      "\n",
      "Hybrid\n",
      "====================\n",
      "# Fuzzy Dataset Size:  2543\n",
      "# Fuzzy Data Division in Confusion Matrix\n",
      "[[   3    0    0]\n",
      " [   3    0    0]\n",
      " [   9    0 2528]]\n",
      "\n",
      "Hybrid Layer 1: Classification without Fuzzy Dataset Result\n",
      "====================\n",
      "Accuracy: 0.78292838400759\n",
      "Confusion Metrix:\n",
      " [[  877    44     0]\n",
      " [ 3602 44469 10004]\n",
      " [  413   580  7468]]\n",
      "\n",
      "Hybrid Layer 2: Clustering with Fuzzy Dataset Result\n",
      "====================\n",
      "Pure:  0.9820833333333333\n",
      "Accuracy: 0.9941014549744397\n",
      "Confusion Metrix:\n",
      " [[   0    0]\n",
      " [  15 2528]]\n",
      "\n",
      "Hybrid Result\n",
      "====================\n",
      "Accuracy: 0.7906\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,3) (2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-f6b7407d83e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfuzzy_data_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhybrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_NB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuzzy_data_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-0cffea316eeb>\u001b[0m in \u001b[0;36mhybrid\u001b[1;34m(clf, fuzzy_threshold, preproc)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhybrid_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Confusion Matrix:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfs_mat_L1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcfs_mat_L2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,3) (2,2) "
     ]
    }
   ],
   "source": [
    "### Naive Bayes + Kmeans\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"Naive Bayes\")\n",
    "print(\"=\"*20)\n",
    "\n",
    "clf_NB = GaussianNB()\n",
    "fuzzy_data_threshold = 0.6\n",
    "\n",
    "hybrid(clf_NB, fuzzy_data_threshold, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Logistic Regression\n",
      "====================\n",
      "# Classification with all Dataset result\n",
      "Accuracy: 0.7218285714285714\n",
      "Confusion Metrix:\n",
      " [[ 2356   168     1]\n",
      " [ 2324 44790 16617]\n",
      " [  227   135  3382]]\n",
      "\n",
      "Hybrid\n",
      "====================\n",
      "# Fuzzy Dataset Size:  9885\n",
      "# Fuzzy Data Division in Confusion Matrix\n",
      "[[  105     2     0]\n",
      " [  384   399 11536]\n",
      " [   93    26 -2660]]\n",
      "\n",
      "Hybrid Layer 1: Classification without Fuzzy Dataset Result\n",
      "====================\n",
      "Accuracy: 0.8763869250603011\n",
      "Confusion Metrix:\n",
      " [[ 2251   166     1]\n",
      " [ 1940 44391  5081]\n",
      " [  134   109  6042]]\n",
      "\n",
      "Hybrid Layer 2: Clustering with Fuzzy Dataset Result\n",
      "====================\n",
      "Pure:  0.9820833333333333\n",
      "Accuracy: 0.9134041476985332\n",
      "Confusion Metrix:\n",
      " [[ 212    0   60]\n",
      " [ 199    1    0]\n",
      " [ 171  426 8816]]\n",
      "\n",
      "Hybrid Result\n",
      "====================\n",
      "Accuracy: 0.8816142857142857\n",
      "Confusion Matrix:\n",
      " [[ 2463   166    61]\n",
      " [ 2139 44392  5081]\n",
      " [  305   535 14858]]\n"
     ]
    }
   ],
   "source": [
    "### Logistric Regression + Kmeans\n",
    "print(\"=\"*20)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"=\"*20)\n",
    "\n",
    "clf_LR=LogisticRegression(fit_intercept=True,C=1e15)\n",
    "fuzzy_data_threshold = 0.6\n",
    "\n",
    "hybrid(clf_LR, fuzzy_data_threshold, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
